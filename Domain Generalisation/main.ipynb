{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“‹ Task 2: Domain Generalization via Invariant & Robust Learning\n",
        "\n",
        "In this task, we explore Domain Generalization (DG), where a model is trained on multiple source domains and must generalize to a completely unseen target domain. We will implement and compare four methods: ERM, IRM, GroupDRO, and SAM.\n",
        "\n",
        "Our setup will use the **PACS dataset**. We will train on the **Art, Cartoon, and Photo** domains, holding out the **Sketch** domain as our unseen test environment, as suggested in the assignment manual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Part 1: Empirical Risk Minimization (ERM) Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1.1. Overview**\n",
        "\n",
        "We begin by establishing a baseline using standard **Empirical Risk Minimization (ERM)**. This approach involves merging all data from the source domains into a single dataset and training a standard classifier on it. This model's performance on the unseen target domain will serve as the benchmark against which we will compare more advanced DG techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1.2. Environment Setup**\n",
        "\n",
        "First, we need to set up the Python environment to ensure the notebook can find and import the DomainBed library from our `code/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Added '/root/IbsATML/PA2/Domain Generalisation/code/domainbed' to Python path.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/venv/main/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Successfully imported DomainBed.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# The path to the 'domainbed' repository inside the 'code' folder\n",
        "# This is the parent directory of the actual 'domainbed' package\n",
        "module_path = os.path.abspath(os.path.join(\".\", \"code\", \"domainbed\"))\n",
        "\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    print(f\"âœ… Added '{module_path}' to Python path.\")\n",
        "\n",
        "# Import the main training function from DomainBed\n",
        "try:\n",
        "    from domainbed.scripts import train\n",
        "\n",
        "    print(\"âœ… Successfully imported DomainBed.\")\n",
        "except ImportError as e:\n",
        "    print(\n",
        "        \"âŒ Error importing DomainBed. Check that the path is correct and the repository is at './code/domainbed'.\"\n",
        "    )\n",
        "    print(e)\n",
        "\n",
        "# Set plotting style for later\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1.3. Experiment Runner Function**\n",
        "\n",
        "To keep our code clean, we'll define a helper function that can launch any DomainBed experiment by taking a dictionary of arguments. This function mimics passing arguments via the command line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(args_dict):\n",
        "    \"\"\"\n",
        "    Builds a command-line command from a dictionary of arguments\n",
        "    and executes the DomainBed training script, setting the PYTHONPATH.\n",
        "    \"\"\"\n",
        "    # Define the path to the directory containing the 'domainbed' package\n",
        "    module_path = os.path.abspath(os.path.join('.', 'code', 'domainbed'))\n",
        "    \n",
        "    # FIX 1: Enclose the module_path in quotes to handle spaces in the directory name.\n",
        "    command = f'PYTHONPATH=\"{module_path}\" python -m domainbed.scripts.train'\n",
        "    \n",
        "    # Append each argument from the dictionary to the command string\n",
        "    for key, value in args_dict.items():\n",
        "        if isinstance(value, bool) and value:\n",
        "            command += f\" --{key}\"\n",
        "        elif not (isinstance(value, bool) and not value):\n",
        "            command += f\" --{key} {value}\"\n",
        "            \n",
        "    print(\"ðŸš€ Executing Command:\")\n",
        "    print(command)\n",
        "    \n",
        "    # Execute the command in the shell\n",
        "    os.system(command)\n",
        "    \n",
        "    # FIX 2: Corrected the typo 'N'/'A' to the string 'N/A'.\n",
        "    print(f\"\\nðŸŽ‰ Training finished for {args_dict.get('algorithm', 'N/A')}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1.4. Run ERM Training**\n",
        "\n",
        "Now, we define the specific parameters for our ERM baseline experiment and launch the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Executing Command:\n",
            "PYTHONPATH=\"/root/IbsATML/PA2/Domain Generalisation/code/domainbed\" python -m domainbed.scripts.train --data_dir ./data/ --dataset PACS --algorithm ERM --test_env 3 --output_dir ./results/erm --hparams_seed 0 --trial_seed 0 --seed 0 --hparams '{\"progress_bar\": true}'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/venv/main/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.12.11\n",
            "\tPyTorch: 2.8.0+cu129\n",
            "\tTorchvision: 0.23.0+cu129\n",
            "\tCUDA: 12.9\n",
            "\tCUDNN: 91002\n",
            "\tNumPy: 2.1.2\n",
            "\tPIL: 11.0.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: ./data/\n",
            "\tdataset: PACS\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"progress_bar\": true}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: ./results/erm\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [3]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tdinov2: False\n",
            "\tfreeze_bn: False\n",
            "\tlars: False\n",
            "\tlinear_steps: 500\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tprogress_bar: True\n",
            "\tresnet18: False\n",
            "\tresnet50_augmix: True\n",
            "\tresnet_dropout: 0.0\n",
            "\tvit: False\n",
            "\tvit_attn_tune: False\n",
            "\tvit_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.1116534472  0.1173594132  0.1897654584  0.2179487179  0.2050898204  0.2095808383  0.0881043257  0.1070063694  0.0000000000  1.9803797007  7.9325380325  0             0.3455526829 \n",
            "0.9914582062  0.9633251834  0.9882729211  0.9636752137  0.9977544910  0.9880239521  0.7665394402  0.7847133758  7.1856287425  0.2129333733  8.1374368668  300           0.0893903550 \n",
            "0.9938987187  0.9633251834  0.9978678038  0.9594017094  0.9992514970  0.9730538922  0.7099236641  0.7184713376  14.371257485  0.0289216487  8.1374368668  600           0.0894707084 \n",
            "0.9957291031  0.9462102689  0.9930703625  0.9487179487  0.9992514970  0.9820359281  0.7722646310  0.7808917197  21.556886227  0.0178145896  8.1374368668  900           0.0898346472 \n",
            "0.9981696156  0.9535452323  0.9978678038  0.9764957265  1.0000000000  0.9850299401  0.7630407125  0.7770700637  28.742514970  0.0159850566  8.1374368668  1200          0.0904598427 \n",
            "0.9987797437  0.9511002445  0.9989339019  0.9551282051  1.0000000000  0.9850299401  0.7595419847  0.7923566879  35.928143712  0.0091424787  8.1374368668  1500          0.0907076430 \n",
            "0.9945088469  0.9266503667  0.9984008529  0.9700854701  1.0000000000  0.9760479042  0.7786259542  0.7821656051  43.113772455  0.0093627543  8.1374368668  1800          0.0907317742 \n",
            "0.9987797437  0.9535452323  0.9994669510  0.9615384615  1.0000000000  0.9880239521  0.8015267176  0.8216560510  50.299401197  0.0115494104  8.1374368668  2100          0.0909458709 \n",
            "0.9987797437  0.9364303178  0.9994669510  0.9786324786  1.0000000000  0.9820359281  0.7340966921  0.7477707006  57.485029940  0.0079947531  8.1374368668  2400          0.0912309162 \n",
            "0.9993898719  0.9511002445  0.9984008529  0.9594017094  0.9992514970  0.9730538922  0.7283715013  0.7579617834  64.670658682  0.0107372985  8.1374368668  2700          0.0910592182 \n",
            "0.9987797437  0.9339853301  1.0000000000  0.9679487179  0.9985029940  0.9640718563  0.7264631043  0.7414012739  71.856287425  0.0092497070  8.1374368668  3000          0.0908624522 \n",
            "0.9981696156  0.9559902200  1.0000000000  0.9508547009  1.0000000000  0.9730538922  0.7722646310  0.8114649682  79.041916167  0.0082652500  8.1374368668  3300          0.0911255137 \n",
            "1.0000000000  0.9633251834  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.7270992366  0.7617834395  86.227544910  0.0035999958  8.1374368668  3600          0.0909262109 \n",
            "0.9969493594  0.9511002445  0.9994669510  0.9658119658  1.0000000000  0.9700598802  0.6914758270  0.7248407643  93.413173652  0.0021751232  8.1374368668  3900          0.0909039990 \n",
            "0.9981696156  0.9608801956  0.9994669510  0.9743589744  1.0000000000  0.9700598802  0.7767175573  0.8076433121  100.59880239  0.0063570482  8.1374368668  4200          0.0912971330 \n",
            "0.9975594875  0.9559902200  1.0000000000  0.9487179487  1.0000000000  0.9790419162  0.7888040712  0.8114649682  107.78443113  0.0101484489  8.1374368668  4500          0.0912606422 \n",
            "0.9975594875  0.9339853301  0.9984008529  0.9636752137  1.0000000000  0.9790419162  0.7942111959  0.8165605096  114.97005988  0.0067233207  8.1374368668  4800          0.0913452784 \n",
            "0.9993898719  0.9486552567  0.9984008529  0.9722222222  1.0000000000  0.9790419162  0.7983460560  0.8382165605  119.76047904  0.0049766661  8.1374368668  5000          0.0910436285 \n",
            "\n",
            "ðŸŽ‰ Training finished for ERM.\n"
          ]
        }
      ],
      "source": [
        "# --- ERM Experiment Configuration ---\n",
        "\n",
        "# 1. Define hyperparameters in their own dictionary.\n",
        "hparams = {\n",
        "    'progress_bar': True\n",
        "    # You can add other hyperparameters like batch_size or lr here too.\n",
        "    # 'batch_size': 32,\n",
        "    # 'lr': 5e-5\n",
        "}\n",
        "\n",
        "# 2. Configure the main experiment arguments.\n",
        "erm_args = {\n",
        "    'data_dir': './data/',\n",
        "    'dataset': 'PACS',\n",
        "    'algorithm': 'ERM',\n",
        "    'test_env': 3,  # The index for the 'Sketch' domain in PACS\n",
        "    'output_dir': './results/erm',\n",
        "    'hparams_seed': 0,\n",
        "    'trial_seed': 0,\n",
        "    'seed': 0,\n",
        "    # 3. Add the hparams dictionary as a JSON string.\n",
        "    # The command line expects a string, so we use json.dumps().\n",
        "    # We wrap it in single quotes for the shell.\n",
        "    'hparams': f\"'{json.dumps(hparams)}'\"\n",
        "}\n",
        "\n",
        "# Launch the experiment\n",
        "run_experiment(erm_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcae15a6",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **Part 2: Invariant Risk Minimization (IRM)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c138323",
      "metadata": {},
      "source": [
        "### **2.1. Overview**\n",
        "\n",
        "Now we move to **Invariant Risk Minimization (IRM)**, as required by Part 2 of the assignment. The core idea behind IRM is to learn a feature representation where the optimal classifier is the same across all training domains. This is intended to prevent the model from relying on spurious, domain-specific correlations, thereby improving generalization to unseen domains.\n",
        "\n",
        "We will first run IRM with its default hyperparameters from DomainBed and then perform an ablation study with a stronger penalty weight to analyze its stability and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956719e1",
      "metadata": {},
      "source": [
        "### **2.2. Run IRM Training (Default Hyperparameters)**\n",
        "\n",
        "We start with the default IRM penalty `irm_lambda=1e2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cf6903c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Executing Command:\n",
            "PYTHONPATH=\"/root/IbsATML/PA2/Domain Generalisation/code/domainbed\" python -m domainbed.scripts.train --data_dir ./data/ --dataset PACS --algorithm IRM --test_env 3 --output_dir ./results/irm_default --hparams_seed 0 --trial_seed 0 --seed 0 --hparams '{\"progress_bar\": true, \"irm_lambda\": 100.0, \"irm_penalty_anneal_iters\": 500}'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/venv/main/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.12.11\n",
            "\tPyTorch: 2.8.0+cu129\n",
            "\tTorchvision: 0.23.0+cu129\n",
            "\tCUDA: 12.9\n",
            "\tCUDNN: 91002\n",
            "\tNumPy: 2.1.2\n",
            "\tPIL: 11.0.0\n",
            "Args:\n",
            "\talgorithm: IRM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: ./data/\n",
            "\tdataset: PACS\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"progress_bar\": true, \"irm_lambda\": 100.0, \"irm_penalty_anneal_iters\": 500}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: ./results/irm_default\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [3]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tdinov2: False\n",
            "\tfreeze_bn: False\n",
            "\tirm_lambda: 100.0\n",
            "\tirm_penalty_anneal_iters: 500\n",
            "\tlars: False\n",
            "\tlinear_steps: 500\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tprogress_bar: True\n",
            "\tresnet18: False\n",
            "\tresnet50_augmix: True\n",
            "\tresnet_dropout: 0.0\n",
            "\tvit: False\n",
            "\tvit_attn_tune: False\n",
            "\tvit_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        nll           penalty       step          step_time    \n",
            "0.1122635754  0.1173594132  0.1897654584  0.2179487179  0.2080838323  0.2095808383  0.0890585242  0.1070063694  0.0000000000  1.9823751450  7.9325442314  1.9803798199  0.0019953740  0             0.3747041225 \n",
            "0.9890176937  0.9633251834  0.9888059701  0.9572649573  0.9992514970  0.9910179641  0.7283715013  0.7464968153  7.1856287425  0.2715274501  8.1374363899  0.2500528763  0.0214745743  300           0.0937796497 \n",
            "0.8364856620  0.8019559902  0.7995735608  0.7606837607  0.9371257485  0.9041916168  0.6103689567  0.6012738854  14.371257485  0.4529195653  8.1390233040  0.0822901678  0.0041631206  600           0.0940159210 \n",
            "0.7211714460  0.7261613692  0.7910447761  0.7884615385  0.7986526946  0.7305389222  0.6332697201  0.6433121019  21.556886227  -13.96678027  8.1390233040  1.4180853146  -0.153848656  900           0.0944469158 \n",
            "0.5216595485  0.5501222494  0.8363539446  0.8012820513  0.4738023952  0.5000000000  0.4875954198  0.4522292994  28.742514970  -56.68304686  8.1390233040  2.2477394044  -0.589307869  1200          0.0957244245 \n",
            "0.5454545455  0.5745721271  0.8256929638  0.8183760684  0.7507485030  0.7155688623  0.2569974555  0.2407643312  35.928143712  -59.33020267  8.1390233040  2.3291109520  -0.616593136  1500          0.0941854517 \n",
            "0.4612568639  0.5061124694  0.8448827292  0.8055555556  0.5179640719  0.5179640719  0.2544529262  0.2343949045  43.113772455  -36.47712758  8.1390233040  2.0347538857  -0.385118812  1800          0.0945545967 \n",
            "0.4972544234  0.5476772616  0.6961620469  0.6346153846  0.5449101796  0.5419161677  0.4688295165  0.4687898089  50.299401197  -28.88329039  8.1390233040  1.9190698512  -0.308023600  2100          0.0938370315 \n",
            "0.3978035387  0.4547677262  0.5991471215  0.5470085470  0.6002994012  0.5568862275  0.3428753181  0.3668789809  57.485029940  -14.41773042  8.1390233040  2.0186487929  -0.164363799  2400          0.0941136297 \n",
            "0.7126296522  0.7041564792  0.7622601279  0.7136752137  0.8570359281  0.7964071856  0.3823155216  0.3643312102  64.670658682  -44.18030029  8.1390233040  2.2926832441  -0.464729836  2700          0.0948632360 \n",
            "0.7071384991  0.7555012225  0.8379530917  0.8183760684  0.8555389222  0.8143712575  0.5314885496  0.5426751592  71.856287425  -49.65922636  8.1390233040  2.1198617830  -0.517790884  3000          0.0944053769 \n",
            "0.6388041489  0.6650366748  0.8267590618  0.7756410256  0.8278443114  0.7694610778  0.5372137405  0.5554140127  79.041916167  -74.29339531  8.1390233040  2.5307419417  -0.768241375  3300          0.0946586005 \n",
            "0.7547284930  0.7506112469  0.8678038380  0.8205128205  0.8488023952  0.8083832335  0.6491730280  0.6649681529  86.227544910  -95.51503682  8.1390233040  2.7619042653  -0.982769420  3600          0.0941479580 \n",
            "0.7504575961  0.7603911980  0.8336886994  0.8076923077  0.8697604790  0.8173652695  0.5524809160  0.5668789809  93.413173652  -70.30653072  8.1390233040  2.6472421871  -0.729537752  3900          0.0947898809 \n",
            "0.7022574741  0.7090464548  0.8267590618  0.7905982906  0.7252994012  0.6856287425  0.4131679389  0.4038216561  100.59880239  -50.12600257  8.1390233040  2.3383591020  -0.524643614  4200          0.0944468315 \n",
            "0.6119585113  0.6039119804  0.7777185501  0.7542735043  0.6953592814  0.6766467066  0.3721374046  0.3745222930  107.78443113  -35.00198434  8.1390233040  2.0799121298  -0.370818964  4500          0.0944624869 \n",
            "0.6308724832  0.6405867971  0.6050106610  0.5769230769  0.7275449102  0.6586826347  0.2057888041  0.2178343949  114.97005988  -2.207576399  8.1390233040  1.8208311947  -0.040284076  4800          0.0950132847 \n",
            "0.5704697987  0.5819070905  0.5831556503  0.5555555556  0.7694610778  0.7005988024  0.3183842239  0.3426751592  119.76047904  -49.89124073  8.1390233040  2.3570684242  -0.522483093  5000          0.0947533798 \n",
            "\n",
            "ðŸŽ‰ Training finished for IRM.\n"
          ]
        }
      ],
      "source": [
        "# --- IRM Experiment Configuration (Default) ---\n",
        "\n",
        "# 1. Define hyperparameters for the default IRM run.\n",
        "hparams_irm_default = {\n",
        "    'progress_bar': True,\n",
        "    'irm_lambda': 1e2,               # Default penalty weight\n",
        "    'irm_penalty_anneal_iters': 500  # Steps to anneal the penalty\n",
        "}\n",
        "\n",
        "# 2. Configure the main experiment arguments.\n",
        "irm_args_default = {\n",
        "    'data_dir': './data/',\n",
        "    'dataset': 'PACS',\n",
        "    'algorithm': 'IRM',\n",
        "    'test_env': 3,  # Sketch domain\n",
        "    'output_dir': './results/irm_default',\n",
        "    'hparams_seed': 0,\n",
        "    'trial_seed': 0,\n",
        "    'seed': 0,\n",
        "    # 3. Add the hparams dictionary as a JSON string.\n",
        "    'hparams': f\"'{json.dumps(hparams_irm_default)}'\"\n",
        "}\n",
        "\n",
        "# Launch the experiment\n",
        "run_experiment(irm_args_default)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68df4754",
      "metadata": {},
      "source": [
        "### **2.3. Ablation Study: Run IRM with Stronger Penalty**\n",
        "\n",
        "As suggested in the assignment, we will now conduct a stability analysis by increasing the penalty weight by an order of magnitude to `irm_lambda=1e3`. This will help us understand how sensitive the IRM algorithm is to this hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d73fd6b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Executing Command:\n",
            "PYTHONPATH=\"/root/IbsATML/PA2/Domain Generalisation/code/domainbed\" python -m domainbed.scripts.train --data_dir ./data/ --dataset PACS --algorithm IRM --test_env 3 --output_dir ./results/irm_stronger_penalty --hparams_seed 0 --trial_seed 0 --seed 0 --hparams '{\"progress_bar\": true, \"irm_lambda\": 1000.0, \"irm_penalty_anneal_iters\": 500}'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/venv/main/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.12.11\n",
            "\tPyTorch: 2.8.0+cu129\n",
            "\tTorchvision: 0.23.0+cu129\n",
            "\tCUDA: 12.9\n",
            "\tCUDNN: 91002\n",
            "\tNumPy: 2.1.2\n",
            "\tPIL: 11.0.0\n",
            "Args:\n",
            "\talgorithm: IRM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: ./data/\n",
            "\tdataset: PACS\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"progress_bar\": true, \"irm_lambda\": 1000.0, \"irm_penalty_anneal_iters\": 500}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: ./results/irm_stronger_penalty\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [3]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tdinov2: False\n",
            "\tfreeze_bn: False\n",
            "\tirm_lambda: 1000.0\n",
            "\tirm_penalty_anneal_iters: 500\n",
            "\tlars: False\n",
            "\tlinear_steps: 500\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tprogress_bar: True\n",
            "\tresnet18: False\n",
            "\tresnet50_augmix: True\n",
            "\tresnet_dropout: 0.0\n",
            "\tvit: False\n",
            "\tvit_attn_tune: False\n",
            "\tvit_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        nll           penalty       step          step_time    \n",
            "0.1122635754  0.1173594132  0.1897654584  0.2179487179  0.2080838323  0.2095808383  0.0890585242  0.1070063694  0.0000000000  1.9823751450  7.9325442314  1.9803798199  0.0019953740  0             0.3537504673 \n",
            "0.9890176937  0.9633251834  0.9888059701  0.9572649573  0.9992514970  0.9910179641  0.7283715013  0.7464968153  7.1856287425  0.2715274501  8.1374363899  0.2500528763  0.0214745743  300           0.0940318831 \n",
            "0.8053691275  0.8141809291  0.6886993603  0.6794871795  0.7754491018  0.7814371257  0.3037531807  0.3197452229  14.371257485  2.3892382437  8.1390233040  0.1369022419  0.0027133155  600           0.0943210840 \n",
            "0.4453935326  0.4449877751  0.5453091684  0.4978632479  0.5067365269  0.4760479042  0.1641221374  0.1872611465  21.556886227  10.015793580  8.1390233040  1.4100490691  0.0086057445  900           0.0941840347 \n",
            "0.6979865772  0.6723716381  0.6972281450  0.6602564103  0.6264970060  0.6167664671  0.3559160305  0.3528662420  28.742514970  -3.780626656  8.1390233040  1.6924613166  -0.005473089  1200          0.0943790531 \n",
            "0.6333129957  0.5843520782  0.5980810235  0.5747863248  0.7851796407  0.7844311377  0.1116412214  0.1108280255  35.928143712  -193.3132791  8.1390233040  1.8656947287  -0.195178972  1500          0.0938761775 \n",
            "0.7144600366  0.6650366748  0.5692963753  0.5277777778  0.8083832335  0.7724550898  0.4974554707  0.5133757962  43.113772455  -37.16908847  8.1390233040  1.7030321217  -0.038872121  1800          0.0941226196 \n",
            "0.6284319707  0.5990220049  0.5655650320  0.5726495726  0.8233532934  0.8173652695  0.4942748092  0.5375796178  50.299401197  -220.0976620  8.1390233040  1.8524492327  -0.221950111  2100          0.0943729885 \n",
            "0.5765710799  0.5330073350  0.4712153518  0.4444444444  0.7500000000  0.7245508982  0.3874045802  0.4101910828  57.485029940  -59.66994474  8.1390233040  1.7958906162  -0.061465833  2400          0.0943614785 \n",
            "0.6760219646  0.7237163814  0.6428571429  0.6602564103  0.8031437126  0.7904191617  0.5623409669  0.5707006369  64.670658682  -95.18196862  8.1390233040  1.8179251480  -0.096999894  2700          0.0943229437 \n",
            "0.6754118365  0.6943765281  0.6839019190  0.7222222222  0.7395209581  0.7185628743  0.5715648855  0.6050955414  71.856287425  -133.0021393  8.1390233040  1.8095665930  -0.134811705  3000          0.0944056892 \n",
            "0.7034777303  0.6845965770  0.6823027719  0.6388888889  0.7417664671  0.6946107784  0.4742366412  0.4840764331  79.041916167  -237.3753295  8.1390233040  1.9727323945  -0.239348061  3300          0.0943865951 \n",
            "0.6247712020  0.6161369193  0.6636460554  0.6239316239  0.7282934132  0.6886227545  0.2808524173  0.2738853503  86.227544910  -89.31617581  8.1390233040  1.8694513667  -0.091185628  3600          0.0945690346 \n",
            "0.5155582672  0.5232273839  0.4013859275  0.3717948718  0.7372754491  0.6916167665  0.1816157761  0.2050955414  93.413173652  -303.9269606  8.1390233040  2.1636436808  -0.306090606  3900          0.0948713875 \n",
            "0.5381330079  0.5647921760  0.5724946695  0.5769230769  0.6556886228  0.5808383234  0.1895674300  0.1694267516  100.59880239  -188.4589695  8.1390233040  2.1656720873  -0.190624640  4200          0.0952563357 \n",
            "0.5716900549  0.5476772616  0.6865671642  0.6623931624  0.6541916168  0.6287425150  0.2627226463  0.2267515924  107.78443113  -237.1855264  8.1390233040  2.1421252724  -0.239327652  4500          0.0953912457 \n",
            "0.6082977425  0.6039119804  0.7308102345  0.6965811966  0.7260479042  0.6856287425  0.2916666667  0.2738853503  114.97005988  -406.5797938  8.1390233040  2.2356682193  -0.408815462  4800          0.0956834284 \n",
            "0.5729103112  0.5672371638  0.6327292111  0.6068376068  0.6953592814  0.6676646707  0.2022900763  0.2178343949  119.76047904  -298.3736445  8.1390233040  2.0793634009  -0.300453007  5000          0.0951651311 \n",
            "\n",
            "ðŸŽ‰ Training finished for IRM.\n"
          ]
        }
      ],
      "source": [
        "# --- IRM Experiment Configuration (Stronger Penalty) ---\n",
        "\n",
        "# 1. Define hyperparameters with the increased penalty.\n",
        "hparams_irm_stronger = {\n",
        "    'progress_bar': True,\n",
        "    'irm_lambda': 1e3,               # 10x stronger penalty\n",
        "    'irm_penalty_anneal_iters': 500\n",
        "}\n",
        "\n",
        "# 2. Configure the main experiment arguments.\n",
        "irm_args_stronger = {\n",
        "    'data_dir': './data/',\n",
        "    'dataset': 'PACS',\n",
        "    'algorithm': 'IRM',\n",
        "    'test_env': 3,  # Sketch domain\n",
        "    'output_dir': './results/irm_stronger_penalty',\n",
        "    'hparams_seed': 0,\n",
        "    'trial_seed': 0,\n",
        "    'seed': 0,\n",
        "    'hparams': f\"'{json.dumps(hparams_irm_stronger)}'\"\n",
        "}\n",
        "\n",
        "# Launch the experiment\n",
        "run_experiment(irm_args_stronger)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Ibs-Kernel",
      "language": "python",
      "name": "ibs-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
