{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 📋 Task 2: Domain Generalization via Invariant & Robust Learning\n",
        "\n",
        "In this task, we explore Domain Generalization (DG), where a model is trained on multiple source domains and must generalize to a completely unseen target domain. We will implement and compare four methods: ERM, IRM, GroupDRO, and SAM.\n",
        "\n",
        "Our setup will use the **PACS dataset**. We will train on the **Art, Cartoon, and Photo** domains, holding out the **Sketch** domain as our unseen test environment, as suggested in the assignment manual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Part 1: Empirical Risk Minimization (ERM) Baseline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1.1. Overview**\n",
        "\n",
        "We begin by establishing a baseline using standard **Empirical Risk Minimization (ERM)**. This approach involves merging all data from the source domains into a single dataset and training a standard classifier on it. This model's performance on the unseen target domain will serve as the benchmark against which we will compare more advanced DG techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **1.2. Environment Setup**\n",
        "\n",
        "First, we need to set up the Python environment to ensure the notebook can find and import the DomainBed library from our `code/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cdc37140",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Added '/root/IbsATML/PA2/Domain Generalisation/code/domainbed' to Python path.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/venv/main/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Successfully imported DomainBed.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# The path to the 'domainbed' repository inside the 'code' folder\n",
        "# This is the parent directory of the actual 'domainbed' package\n",
        "module_path = os.path.abspath(os.path.join(\".\", \"code\", \"domainbed\"))\n",
        "\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    print(f\"✅ Added '{module_path}' to Python path.\")\n",
        "\n",
        "# Import the main training function from DomainBed\n",
        "try:\n",
        "    from domainbed.scripts import train\n",
        "\n",
        "    print(\"✅ Successfully imported DomainBed.\")\n",
        "except ImportError as e:\n",
        "    print(\n",
        "        \"❌ Error importing DomainBed. Check that the path is correct and the repository is at './code/domainbed'.\"\n",
        "    )\n",
        "    print(e)\n",
        "\n",
        "# Set plotting style for later\n",
        "sns.set_theme(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e261918",
      "metadata": {},
      "source": [
        "### **1.3. Experiment Runner Function**\n",
        "\n",
        "To keep our code clean, we'll define a helper function that can launch any DomainBed experiment by taking a dictionary of arguments. This function mimics passing arguments via the command line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "748ae24e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(args_dict):\n",
        "    \"\"\"\n",
        "    Builds a command-line command from a dictionary of arguments\n",
        "    and executes the DomainBed training script, setting the PYTHONPATH.\n",
        "    \"\"\"\n",
        "    # Define the path to the directory containing the 'domainbed' package\n",
        "    module_path = os.path.abspath(os.path.join('.', 'code', 'domainbed'))\n",
        "    \n",
        "    # FIX 1: Enclose the module_path in quotes to handle spaces in the directory name.\n",
        "    command = f'PYTHONPATH=\"{module_path}\" python -m domainbed.scripts.train'\n",
        "    \n",
        "    # Append each argument from the dictionary to the command string\n",
        "    for key, value in args_dict.items():\n",
        "        if isinstance(value, bool) and value:\n",
        "            command += f\" --{key}\"\n",
        "        elif not (isinstance(value, bool) and not value):\n",
        "            command += f\" --{key} {value}\"\n",
        "            \n",
        "    print(\"🚀 Executing Command:\")\n",
        "    print(command)\n",
        "    \n",
        "    # Execute the command in the shell\n",
        "    os.system(command)\n",
        "    \n",
        "    # FIX 2: Corrected the typo 'N'/'A' to the string 'N/A'.\n",
        "    print(f\"\\n🎉 Training finished for {args_dict.get('algorithm', 'N/A')}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94e0763e",
      "metadata": {},
      "source": [
        "### **1.4. Run ERM Training**\n",
        "\n",
        "Now, we define the specific parameters for our ERM baseline experiment and launch the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9ee8860d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Executing Command:\n",
            "PYTHONPATH=\"/root/IbsATML/PA2/Domain Generalisation/code/domainbed\" python -m domainbed.scripts.train --data_dir ./data/ --dataset PACS --algorithm ERM --test_env 3 --output_dir ./results/erm --hparams_seed 0 --trial_seed 0 --seed 0 --hparams '{\"progress_bar\": true}'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/venv/main/lib/python3.12/site-packages/outdated/__init__.py:36: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import parse_version\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment:\n",
            "\tPython: 3.12.11\n",
            "\tPyTorch: 2.8.0+cu129\n",
            "\tTorchvision: 0.23.0+cu129\n",
            "\tCUDA: 12.9\n",
            "\tCUDNN: 91002\n",
            "\tNumPy: 2.1.2\n",
            "\tPIL: 11.0.0\n",
            "Args:\n",
            "\talgorithm: ERM\n",
            "\tcheckpoint_freq: None\n",
            "\tdata_dir: ./data/\n",
            "\tdataset: PACS\n",
            "\tholdout_fraction: 0.2\n",
            "\thparams: {\"progress_bar\": true}\n",
            "\thparams_seed: 0\n",
            "\toutput_dir: ./results/erm\n",
            "\tsave_model_every_checkpoint: False\n",
            "\tseed: 0\n",
            "\tskip_model_save: False\n",
            "\tsteps: None\n",
            "\ttask: domain_generalization\n",
            "\ttest_envs: [3]\n",
            "\ttrial_seed: 0\n",
            "\tuda_holdout_fraction: 0\n",
            "HParams:\n",
            "\tbatch_size: 32\n",
            "\tclass_balanced: False\n",
            "\tdata_augmentation: True\n",
            "\tdinov2: False\n",
            "\tfreeze_bn: False\n",
            "\tlars: False\n",
            "\tlinear_steps: 500\n",
            "\tlr: 5e-05\n",
            "\tnonlinear_classifier: False\n",
            "\tprogress_bar: True\n",
            "\tresnet18: False\n",
            "\tresnet50_augmix: True\n",
            "\tresnet_dropout: 0.0\n",
            "\tvit: False\n",
            "\tvit_attn_tune: False\n",
            "\tvit_dropout: 0.0\n",
            "\tweight_decay: 0.0\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/venv/main/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    \n",
            "0.1116534472  0.1173594132  0.1897654584  0.2179487179  0.2050898204  0.2095808383  0.0881043257  0.1070063694  0.0000000000  1.9803797007  7.9325380325  0             0.3455526829 \n",
            "0.9914582062  0.9633251834  0.9882729211  0.9636752137  0.9977544910  0.9880239521  0.7665394402  0.7847133758  7.1856287425  0.2129333733  8.1374368668  300           0.0893903550 \n",
            "0.9938987187  0.9633251834  0.9978678038  0.9594017094  0.9992514970  0.9730538922  0.7099236641  0.7184713376  14.371257485  0.0289216487  8.1374368668  600           0.0894707084 \n",
            "0.9957291031  0.9462102689  0.9930703625  0.9487179487  0.9992514970  0.9820359281  0.7722646310  0.7808917197  21.556886227  0.0178145896  8.1374368668  900           0.0898346472 \n",
            "0.9981696156  0.9535452323  0.9978678038  0.9764957265  1.0000000000  0.9850299401  0.7630407125  0.7770700637  28.742514970  0.0159850566  8.1374368668  1200          0.0904598427 \n",
            "0.9987797437  0.9511002445  0.9989339019  0.9551282051  1.0000000000  0.9850299401  0.7595419847  0.7923566879  35.928143712  0.0091424787  8.1374368668  1500          0.0907076430 \n",
            "0.9945088469  0.9266503667  0.9984008529  0.9700854701  1.0000000000  0.9760479042  0.7786259542  0.7821656051  43.113772455  0.0093627543  8.1374368668  1800          0.0907317742 \n",
            "0.9987797437  0.9535452323  0.9994669510  0.9615384615  1.0000000000  0.9880239521  0.8015267176  0.8216560510  50.299401197  0.0115494104  8.1374368668  2100          0.0909458709 \n",
            "0.9987797437  0.9364303178  0.9994669510  0.9786324786  1.0000000000  0.9820359281  0.7340966921  0.7477707006  57.485029940  0.0079947531  8.1374368668  2400          0.0912309162 \n",
            "0.9993898719  0.9511002445  0.9984008529  0.9594017094  0.9992514970  0.9730538922  0.7283715013  0.7579617834  64.670658682  0.0107372985  8.1374368668  2700          0.0910592182 \n",
            "0.9987797437  0.9339853301  1.0000000000  0.9679487179  0.9985029940  0.9640718563  0.7264631043  0.7414012739  71.856287425  0.0092497070  8.1374368668  3000          0.0908624522 \n",
            "0.9981696156  0.9559902200  1.0000000000  0.9508547009  1.0000000000  0.9730538922  0.7722646310  0.8114649682  79.041916167  0.0082652500  8.1374368668  3300          0.0911255137 \n",
            "1.0000000000  0.9633251834  1.0000000000  0.9529914530  1.0000000000  0.9730538922  0.7270992366  0.7617834395  86.227544910  0.0035999958  8.1374368668  3600          0.0909262109 \n",
            "0.9969493594  0.9511002445  0.9994669510  0.9658119658  1.0000000000  0.9700598802  0.6914758270  0.7248407643  93.413173652  0.0021751232  8.1374368668  3900          0.0909039990 \n",
            "0.9981696156  0.9608801956  0.9994669510  0.9743589744  1.0000000000  0.9700598802  0.7767175573  0.8076433121  100.59880239  0.0063570482  8.1374368668  4200          0.0912971330 \n",
            "0.9975594875  0.9559902200  1.0000000000  0.9487179487  1.0000000000  0.9790419162  0.7888040712  0.8114649682  107.78443113  0.0101484489  8.1374368668  4500          0.0912606422 \n",
            "0.9975594875  0.9339853301  0.9984008529  0.9636752137  1.0000000000  0.9790419162  0.7942111959  0.8165605096  114.97005988  0.0067233207  8.1374368668  4800          0.0913452784 \n",
            "0.9993898719  0.9486552567  0.9984008529  0.9722222222  1.0000000000  0.9790419162  0.7983460560  0.8382165605  119.76047904  0.0049766661  8.1374368668  5000          0.0910436285 \n",
            "\n",
            "🎉 Training finished for ERM.\n"
          ]
        }
      ],
      "source": [
        "# --- ERM Experiment Configuration ---\n",
        "\n",
        "# 1. Define hyperparameters in their own dictionary.\n",
        "hparams = {\n",
        "    'progress_bar': True\n",
        "    # You can add other hyperparameters like batch_size or lr here too.\n",
        "    # 'batch_size': 32,\n",
        "    # 'lr': 5e-5\n",
        "}\n",
        "\n",
        "# 2. Configure the main experiment arguments.\n",
        "erm_args = {\n",
        "    'data_dir': './data/',\n",
        "    'dataset': 'PACS',\n",
        "    'algorithm': 'ERM',\n",
        "    'test_env': 3,  # The index for the 'Sketch' domain in PACS\n",
        "    'output_dir': './results/erm',\n",
        "    'hparams_seed': 0,\n",
        "    'trial_seed': 0,\n",
        "    'seed': 0,\n",
        "    # 3. Add the hparams dictionary as a JSON string.\n",
        "    # The command line expects a string, so we use json.dumps().\n",
        "    # We wrap it in single quotes for the shell.\n",
        "    'hparams': f\"'{json.dumps(hparams)}'\"\n",
        "}\n",
        "\n",
        "# Launch the experiment\n",
        "run_experiment(erm_args)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Ibs-Kernel",
      "language": "python",
      "name": "ibs-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
